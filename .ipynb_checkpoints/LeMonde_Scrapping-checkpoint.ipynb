{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "requete = requests.get(\"https://www.lemonde.fr/\")\n",
    "page = requete.content\n",
    "soupAccueil = BeautifulSoup(page)\n",
    "\n",
    "# cas d'article live\n",
    "live = False\n",
    "if(soupAccueil.find(\"div\", {\"class\": \"article article--main\"}).find(\"span\", {\"class\": \"icon__label-live icon__label-live--xl\"})):\n",
    "    live = True\n",
    "print(live)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not live):\n",
    "    mainArticle = {\n",
    "        \"title\": soupAccueil.find(\"div\", {\"class\": \"article article--main\"}).find(\"span\", {\"class\": \"article__title-label\"}).get_text().replace(u'\\xa0', u' '),\n",
    "        \"link\": soupAccueil.find(\"div\", {\"class\": \"article article--main\"}).a[\"href\"]\n",
    "    }\n",
    "\n",
    "    requete = requests.get(mainArticle[\"link\"])\n",
    "    page = requete.content\n",
    "    soupMainArticle = BeautifulSoup(page)\n",
    "    mainArticle[\"subTitle\"] = soupMainArticle.find(\"p\", {\"class\": \"article__desc\"}).get_text().replace(u'\\xa0', u' ')\n",
    "    paragraphes = soupMainArticle.find_all(\"p\", {\"class\": \"article__paragraph\"})\n",
    "    mainArticle[\"content\"] = list(map(lambda para: para.get_text().replace(u'\\xa0', u' '), paragraphes))\n",
    "\n",
    "\n",
    "    print(mainArticle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C’est un tremblement de terre dont l’origine est rare. Un séisme de magnitude 3,5, lié au développement d’un projet de centrale géothermique, a réveillé, vendredi 4 décembre, les habitants de l’agglomération de Strasbourg.', 'Peu après, une autre secousse de magnitude 2,8 a entraîné l’arrêt des activités de la centrale par l’exploitant, et la remise en cause du projet par des élus. Cette secousse survient après plusieurs autres tremblements de terre moins intenses enregistrés depuis treize mois et liés à l’activité de géothermie, pilier de la transition énergétique en Alsace.', 'Le Réseau national de surveillance sismique (Rénass) a classé ce séisme survenu à 6 h 59 comme « induit », c’est-à-dire provoqué par l’activité humaine. L’épicentre du séisme se trouve à une dizaine de kilomètres au nord de Strasbourg, à proximité d’un site accueillant un projet de centrale géothermique conduit par l’entreprise Fonroche, pas encore mise en exploitation, sur les communes de Vendenheim et Reichstett.', 'Sur le site, deux puits ont été creusés à 5 kilomètres de profondeur afin de pomper l’eau chaude souterraine pour en exploiter en surface le potentiel énergétique, avant de la réinjecter vers le sous-sol.', 'Un porte-parole de Fonroche a confirmé à l’Agence France-Presse (AFP) que la secousse était bien liée à ses activités. Dans un communiqué, la société a annoncé le déclenchement d’une procédure de diminution progressive de la circulation d’eau dans les puits, vers un « arrêt total ». La procédure « se déroulera sur environ un mois », précise Fonroche.', 'La secousse a rapidement été commentée sur les réseaux sociaux. « A Strasbourg, on n’utilise pas de réveil, on a des séismes magnitude 3,5 à 7 heures », a écrit un journaliste strasbourgeois sur Twitter.', 'Beaucoup d’internautes réclament l’arrêt des activités de géothermie à Reichstett-Vendenheim. La secousse a provoqué « une psychose » chez les habitants des communes proches de l’épicentre, a déclaré à l’AFP Georges Schuler, le maire de Reichstett.', 'Celui-ci a fait état de quelques dégâts matériels et de nombreux appels de riverains paniqués. « C’est la goutte d’eau qui fait déborder le vase. Nous demandons l’arrêt définitif de l’exploitation du site », a-t-il déclaré à l’AFP… juste avant une nouvelle réplique, de magnitude 2,8 enregistrée dans la même zone à 11 h 10.', 'D’autres élus des groupes d’opposition de la métropole de Strasbourg se sont également exprimés pour dénoncer le projet. « Arrêtons de jouer aux apprentis sorciers », a intimé Jean-Philippe Vetter, président du groupe Les Républicains, dénonçant « l’aveuglement idéologique » des élus écologistes favorables à la centrale de géothermie, et exigeant une transparence « totale ».', '« Nouveau tremblement de terre à 6 h 59 ce matin à proximité de Strasbourg (…) on a tous pu le ressentir #ReNass. Le 11e en un mois, ça fait beaucoup et relance le débat sur la géothermie profonde. Le débat doit être complet et transparent », a réagi sur Twitter Alain Fontanel, conseiller municipal strasbourgeois d’opposition.', 'Un abandon du projet n’est cependant pas à l’ordre du jour, a fait savoir le porte-parole de Fonroche. « Le retour d’expérience des autres centrales dans la vallée rhénane montre qu’une fois qu’elles tournent, elles ne provoquent pas spécialement de surréaction de la roche ».', 'La société avait obtenu en 2016 du préfet une autorisation de forage, contre l’avis des élus des communes concernées. Elle a jusqu’ici investi près de 90 millions d’euros dans cette centrale, qui vise à alimenter l’équivalent de 10 000 logements en électricité, et 26 000 en chaleur directe.', 'La controverse s’amplifie depuis l’enregistrement d’un séisme de magnitude 3,1 le 12 novembre 2019. Son épicentre était situé à 5 kilomètres du site de géothermie. Considéré comme étant d’origine naturelle par Fonroche, il a été classé « induit » par le Rénass.', '« Dans la sismicité induite, il faut distinguer deux phénomènes », explique Jean Schmittbuhl, directeur de recherche au CNRS en sismologie. « Il y a ceux liés à la mise en pression très directe du fluide. C’est ce qui s’est passé ces dernières semaines jusqu’à ce matin. Et il y a la sismicité dite “déclenchée”, quand le système, naturellement, était très proche de rompre, et que l’activité humaine constitue l’élément déclencheur. C’est ce qui s’est vraisemblablement passé l’an dernier. »', 'D’autres expertises, menées à la demande de la préfecture par l’Institut national de l’environnement industriel et des risques (Ineris) et par le Bureau de recherches géologiques et minières (BRGM) n’ont pas permis de définir avec certitude l’origine du séisme de 2019.', 'Celui-ci avait néanmoins entraîné l’arrêt des opérations d’injection d’eau sur le site de géothermie, mais la construction de la centrale de transformation de l’énergie thermique en électricité s’était, elle, poursuivie.', 'En septembre, la préfecture du Bas-Rhin avait autorisé la réalisation de tests dans les puits de la centrale afin de trancher la question de l’origine du séisme. Ils ont été suivis de nouvelles secousses répétées, une dizaine en deux semaines entre la fin d’octobre et le début du mois de novembre, ce qui avait conduit la préfecture du Bas-Rhin à suspendre les opérations. Fonroche a reconnu que ces secousses des deux derniers mois étaient dues à ses tests.']\n"
     ]
    }
   ],
   "source": [
    "#Récupère article sur un lien\n",
    "if(live):\n",
    "    requete = requests.get(\"https://www.lemonde.fr/planete/article/2020/12/04/un-nouveau-seisme-d-origine-humaine-reveille-l-agglomeration-de-strasbourg_6062150_3244.html\")\n",
    "    page = requete.content\n",
    "    soupAccueil = BeautifulSoup(page)\n",
    "    \n",
    "    mainArticle = {\n",
    "        \"title\": soupAccueil.find(\"h1\", {\"class\": \"article__title\"}).get_text().replace(u'\\xa0', u' '),\n",
    "        \"link\": \"https://www.lemonde.fr/planete/article/2020/12/04/un-nouveau-seisme-d-origine-humaine-reveille-l-agglomeration-de-strasbourg_6062150_3244.html\"\n",
    "    }\n",
    "\n",
    "    requete = requests.get(mainArticle[\"link\"])\n",
    "    page = requete.content\n",
    "    soupMainArticle = BeautifulSoup(page)\n",
    "    mainArticle[\"subTitle\"] = soupMainArticle.find(\"p\", {\"class\": \"article__desc\"}).get_text().replace(u'\\xa0', u' ')\n",
    "    paragraphes = soupMainArticle.find_all(\"p\", {\"class\": \"article__paragraph\"})\n",
    "    mainArticle[\"content\"] = list(map(lambda para: para.get_text().replace(u'\\xa0', u' '), paragraphes))\n",
    "\n",
    "    print(mainArticle[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:34: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:34: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<ipython-input-6-a5a0d2a7cce1>:34: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if word.pos_ is \"PUNCT\":\n",
      "<ipython-input-6-a5a0d2a7cce1>:53: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if score < lowest_score or lowest_score is -1:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a5a0d2a7cce1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-a5a0d2a7cce1>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m# 4, 5, 6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mranked\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ranked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msentence_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moccurrences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# 7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a5a0d2a7cce1>\u001b[0m in \u001b[0;36mget_ranked\u001b[1;34m(sentences, sentence_count, occurrences)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlowest_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;31m# Maintain chronological order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mranked\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m                 \u001b[0mranked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mranked\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import sys\n",
    "import spacy\n",
    "\n",
    "def main():\n",
    "    args = sys.argv\n",
    "\n",
    "    filename = mainArticle[\"title\"]\n",
    "\n",
    "    sentence_count = 3\n",
    "\n",
    "    # Process file contents\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    doc = nlp(\" \".join(mainArticle[\"content\"]))\n",
    "\n",
    "    # 1, 2, 3\n",
    "    occurrences = {}\n",
    "    def fill_occurrences(word):\n",
    "        word_lemma = lemma(word)\n",
    "        count = occurrences.get(word_lemma, 0)\n",
    "        count += 1\n",
    "        occurrences[word_lemma] = count\n",
    "\n",
    "    each_word(doc, fill_occurrences)\n",
    "\n",
    "    # 4, 5, 6\n",
    "    ranked = get_ranked(doc.sents, sentence_count, occurrences)\n",
    "\n",
    "    # 7\n",
    "    print(\" \".join([x['sentence'].text for x in ranked]))\n",
    "\n",
    "def each_word(words, func):\n",
    "    for word in words:\n",
    "        if word.pos_ is \"PUNCT\":\n",
    "            continue\n",
    "\n",
    "        func(word)\n",
    "\n",
    "def get_ranked(sentences, sentence_count, occurrences):\n",
    "    # Maintain ranked sentences for easy output\n",
    "    ranked = []\n",
    "\n",
    "    # Maintain the lowest score for easy removal\n",
    "    lowest_score = -1\n",
    "    lowest = 0\n",
    "\n",
    "    for sent in sentences:\n",
    "        # Fill ranked if not at capacity\n",
    "        if len(ranked) < sentence_count:\n",
    "            score = get_score(occurrences, sent)\n",
    "\n",
    "            # Maintain lowest score\n",
    "            if score < lowest_score or lowest_score is -1:\n",
    "                lowest = len(ranked) + 1\n",
    "                lowest_score = score\n",
    "\n",
    "            ranked.append({'sentence': sent, 'score': score})\n",
    "            continue\n",
    "\n",
    "        score = get_score(occurrences, sent)\n",
    "        # Insert if score is greater\n",
    "        if score > lowest_score:\n",
    "            # Maintain chronological order\n",
    "            for i in xrange(lowest, len(ranked) - 1):\n",
    "                ranked[i] = ranked[i+1]\n",
    "\n",
    "            ranked[len(ranked) - 1] = {'sentence': sent, 'score': score}\n",
    "\n",
    "            # Reset lowest_score\n",
    "            lowest_score = ranked[0]['score']\n",
    "            lowest = 0\n",
    "            for i in xrange(0, len(ranked)):\n",
    "                if ranked[i]['score'] < lowest_score:\n",
    "                    lowest = i\n",
    "                    lowest_score = ranked[i]['score']\n",
    "\n",
    "    return ranked\n",
    "\n",
    "def lemma(word):\n",
    "    return word.lemma_\n",
    "\n",
    "def get_score(occurrences, sentence):\n",
    "    class Totaler:\n",
    "        def __init__(self):\n",
    "            self.score = 0\n",
    "        def __call__(self, word):\n",
    "            self.score += occurrences.get(lemma(word), 0)\n",
    "        def total(self):\n",
    "            # Should the score be divided by total words?\n",
    "            return self.score\n",
    "\n",
    "    totaler = Totaler()\n",
    "\n",
    "    each_word(sentence, totaler)\n",
    "\n",
    "    return totaler.total()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytextrank in c:\\users\\quentin\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from pytextrank) (2.5)\n",
      "Requirement already satisfied: graphviz in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from pytextrank) (0.15)\n",
      "Requirement already satisfied: coverage in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from pytextrank) (5.3)\n",
      "Requirement already satisfied: spacy in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from pytextrank) (2.3.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from networkx->pytextrank) (4.4.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (0.8.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (4.50.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.19.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (0.9.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (2.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (50.3.0.post20201006)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (3.0.2)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy->pytextrank) (7.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy->pytextrank) (3.0.4)\n",
      "Requirement already satisfied: utils in c:\\users\\quentin\\anaconda3\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (50.3.0.post20201006)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.50.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: thinc==7.4.1 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\quentin\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install pytextrank\n",
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "[E046] Can't retrieve unregistered extension attribute 'sents'. Did you forget to call the `set_extension` method?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-615dc3491db9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# examine the top-ranked phrases in the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\tokens\\underscore.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE046\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msetter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extensions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: [E046] Can't retrieve unregistered extension attribute 'sents'. Did you forget to call the `set_extension` method?"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "# example text\n",
    "text = \" \".join(mainArticle[\"content\"])\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "tr = pytextrank.TextRank()\n",
    "nlp.add_pipe(tr.PipelineComponent, name=\"textrank\", last=True)\n",
    "\n",
    "doc = nlp(text)\n",
    "print(doc._.sents)\n",
    "\n",
    "# examine the top-ranked phrases in the document\n",
    "for p in doc._.phrases:\n",
    "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\n",
    "    print(p.chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Quentin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import spacy\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarize Text: \n",
      " « Arrêtons de jouer aux apprentis sorciers », a intimé Jean-Philippe Vetter, président du groupe Les Républicains, dénonçant « l’aveuglement idéologique » des élus écologistes favorables à la centrale de géothermie, et exigeant une transparence « totale ».. « C’est la goutte d’eau qui fait déborder le vase.. La secousse a provoqué « une psychose » chez les habitants des communes proches de l’épicentre, a déclaré à l’AFP Georges Schuler, le maire de Reichstett.. « Nouveau tremblement de terre à 6 h 59 ce matin à proximité de Strasbourg (…) on a tous pu le ressentir #ReNass.. L’épicentre du séisme se trouve à une dizaine de kilomètres au nord de Strasbourg, à proximité d’un site accueillant un projet de centrale géothermique conduit par l’entreprise Fonroche, pas encore mise en exploitation, sur les communes de Vendenheim et Reichstett.\n"
     ]
    }
   ],
   "source": [
    "def sentence_similarity(sent1, sent2, stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    " \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    " \n",
    "    all_words = list(set(sent1 + sent2))\n",
    " \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    " \n",
    "    # build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector1[all_words.index(w)] += 1\n",
    " \n",
    "    # build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if w in stopwords:\n",
    "            continue\n",
    "        vector2[all_words.index(w)] += 1\n",
    " \n",
    "    return 1 - cosine_distance(vector1, vector2)\n",
    " \n",
    "def build_similarity_matrix(sentences, stop_words):\n",
    "    # Create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
    " \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1 == idx2: #ignore if both are same sentences\n",
    "                continue \n",
    "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
    "\n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "def generate_summary(top_n=5):\n",
    " \n",
    "    stop_words = stopwords.words('french')\n",
    "    summarize_text = []\n",
    "\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "    \n",
    "    # Step 1 - Read text anc split it\n",
    "    text = \" \".join(mainArticle[\"content\"])\n",
    "    doc = nlp(text)\n",
    "    sentences =  [X.text for X in doc.sents]\n",
    "\n",
    "    # Step 2 - Generate Similary Martix across sentences\n",
    "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
    "\n",
    "    # Step 3 - Rank sentences in similarity martix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "\n",
    "    # Step 4 - Sort the rank and pick top sentences\n",
    "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
    "    # print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
    "\n",
    "    for i in range(top_n):\n",
    "      summarize_text.append(ranked_sentence[i][1])\n",
    "\n",
    "    # Step 5 - Offcourse, output the summarize texr\n",
    "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))\n",
    "\n",
    "# let's begin\n",
    "generate_summary(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
